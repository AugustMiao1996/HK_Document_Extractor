#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œå¤„ç†å¯åŠ¨è„šæœ¬
Parallel Processing Launcher for Hong Kong Court Document Extractor

Author: AI Assistant
Version: 1.0
"""

import sys
import argparse
import time
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
src_dir = current_dir / 'src'
sys.path.insert(0, str(src_dir))

try:
    from parallel_processor import ParallelBatchProcessor
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='é¦™æ¸¯æ³•åº­æ–‡ä¹¦ä¿¡æ¯æå–å™¨ - å¹¶è¡Œç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸš€ å¹¶è¡Œå¤„ç†ç¤ºä¾‹:
  # è‡ªåŠ¨æ£€æµ‹æœ€ä½³è¿›ç¨‹æ•°ï¼Œå¤„ç†HCAæ–‡ä»¶å¤¹
  python run_parallel.py --input ../HK/HCA --output json
  
  # æŒ‡å®šä½¿ç”¨4ä¸ªè¿›ç¨‹
  python run_parallel.py --input ../HK/HCA --output all --workers 4
  
  # å¤„ç†500ä¸ªæ–‡æ¡£
  python run_parallel.py --input ../POC500ä¸ªæ–‡ä»¶ --output all --workers 6
  
âš¡ æ€§èƒ½æå‡ï¼šé¢„æœŸå¯è·å¾— 3-6å€ é€Ÿåº¦æå‡ï¼
"""
    )
    
    parser.add_argument(
        '--input', '-i',
        required=True,
        help='è¾“å…¥ç›®å½•è·¯å¾„ (åŒ…å«PDFæ–‡ä»¶çš„ç›®å½•)'
    )
    
    parser.add_argument(
        '--output', '-o',
        choices=['json', 'csv', 'excel', 'all'],
        default='json',
        help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: json)'
    )
    
    parser.add_argument(
        '--workers', '-w',
        type=int,
        default=None,
        help='å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)'
    )
    
    parser.add_argument(
        '--output-dir',
        default='output',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: output)'
    )
    
    parser.add_argument(
        '--log-dir',
        default='logs',
        help='æ—¥å¿—ç›®å½• (é»˜è®¤: logs)'
    )
    
    parser.add_argument(
        '--test', '-t',
        action='store_true',
        help='æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰10ä¸ªæ–‡ä»¶'
    )
    
    parser.add_argument(
        '--benchmark', '-b',
        action='store_true',
        help='æ€§èƒ½æµ‹è¯•ï¼šå¯¹æ¯”ä¸²è¡Œvså¹¶è¡Œå¤„ç†é€Ÿåº¦'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è¯¦ç»†è¾“å‡ºæ¨¡å¼'
    )
    
    return parser

def print_welcome():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("=" * 60)
    print(" ğŸš€ é¦™æ¸¯æ³•åº­æ–‡ä¹¦ä¿¡æ¯æå–å™¨ - å¹¶è¡Œç‰ˆ")
    print(" Hong Kong Court Document Extractor - Parallel Version")
    print(" Version: 1.0")
    print("=" * 60)

def run_benchmark(input_dir: str, args):
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("\nğŸ”¥ æ€§èƒ½æµ‹è¯•æ¨¡å¼")
    print("å¯¹æ¯”ä¸²è¡Œå¤„ç† vs å¹¶è¡Œå¤„ç†é€Ÿåº¦...")
    
    # è·å–å‰10ä¸ªPDFæ–‡ä»¶ç”¨äºæµ‹è¯•
    from pathlib import Path
    pdf_files = list(Path(input_dir).glob("*.pdf"))[:10]
    
    if len(pdf_files) < 5:
        print("âŒ æµ‹è¯•æ–‡ä»¶æ•°é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦5ä¸ªPDFæ–‡ä»¶")
        return
    
    print(f"ğŸ“Š ä½¿ç”¨ {len(pdf_files)} ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•")
    
    # 1. ä¸²è¡Œå¤„ç†æµ‹è¯•
    print("\n1ï¸âƒ£ ä¸²è¡Œå¤„ç†æµ‹è¯•...")
    from processor import BatchProcessor
    serial_processor = BatchProcessor(args.output_dir, args.log_dir)
    
    start_time = time.time()
    serial_results = []
    for pdf_file in pdf_files:
        from extractor import DocumentExtractor
        extractor = DocumentExtractor()
        result = extractor.process_pdf(str(pdf_file))
        if result:
            serial_results.append(result)
    serial_time = time.time() - start_time
    
    # 2. å¹¶è¡Œå¤„ç†æµ‹è¯•
    print("\n2ï¸âƒ£ å¹¶è¡Œå¤„ç†æµ‹è¯•...")
    parallel_processor = ParallelBatchProcessor(
        args.output_dir, args.log_dir, args.workers
    )
    
    start_time = time.time()
    # åˆ›å»ºä¸´æ—¶ç›®å½•åªåŒ…å«æµ‹è¯•æ–‡ä»¶
    import tempfile
    import shutil
    with tempfile.TemporaryDirectory() as temp_dir:
        for pdf_file in pdf_files:
            shutil.copy2(pdf_file, temp_dir)
        parallel_results = parallel_processor.process_directory_parallel(temp_dir)
    parallel_time = time.time() - start_time
    
    # 3. ç»“æœå¯¹æ¯”
    print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"  ä¸²è¡Œå¤„ç†: {serial_time:.2f} ç§’ ({len(serial_results)} ä¸ªæ–‡ä»¶)")
    print(f"  å¹¶è¡Œå¤„ç†: {parallel_time:.2f} ç§’ ({len(parallel_results)} ä¸ªæ–‡ä»¶)")
    
    if parallel_time > 0:
        speedup = serial_time / parallel_time
        print(f"  ğŸš€ æ€§èƒ½æå‡: {speedup:.1f}x å€")
        
        if speedup > 1.5:
            print("  âœ… å¹¶è¡Œå¤„ç†æ•ˆæœæ˜¾è‘—ï¼")
        elif speedup > 1.1:
            print("  âš ï¸ å¹¶è¡Œå¤„ç†æœ‰ä¸€å®šæå‡")
        else:
            print("  âŒ å¹¶è¡Œå¤„ç†æå‡ä¸æ˜æ˜¾ï¼Œå¯èƒ½ç”±äºæ–‡ä»¶è¿‡å°æˆ–I/Oç“¶é¢ˆ")

def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    if args.verbose:
        print_welcome()
    
    # éªŒè¯è¾“å…¥ç›®å½•
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    if not input_path.is_dir():
        print(f"âŒ é”™è¯¯: æŒ‡å®šè·¯å¾„ä¸æ˜¯ç›®å½•: {args.input}")
        sys.exit(1)
    
    # æ£€æŸ¥PDFæ–‡ä»¶
    pdf_files = list(input_path.glob("*.pdf"))
    if not pdf_files:
        print(f"âš ï¸ è­¦å‘Š: åœ¨ç›®å½• {args.input} ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    
    # æ€§èƒ½æµ‹è¯•æ¨¡å¼
    if args.benchmark:
        run_benchmark(args.input, args)
        return
    
    # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰10ä¸ªæ–‡ä»¶
    if args.test:
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰10ä¸ªæ–‡ä»¶")
        import tempfile
        import shutil
        temp_dir = tempfile.mkdtemp()
        for pdf_file in pdf_files[:10]:
            shutil.copy2(pdf_file, temp_dir)
        args.input = temp_dir
    
    try:
        # åˆ›å»ºå¹¶è¡Œå¤„ç†å™¨
        processor = ParallelBatchProcessor(
            output_dir=args.output_dir,
            log_dir=args.log_dir,
            max_workers=args.workers
        )
        
        # è¿è¡Œå¹¶è¡Œå¤„ç†
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç†ç›®å½•: {args.input}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ğŸ“„ è¾“å‡ºæ ¼å¼: {args.output}")
        print(f"âš¡ è¿›ç¨‹æ•°: {processor.max_workers}")
        
        summary = processor.run(
            input_dir=args.input,
            output_format=args.output
        )
        
        # æ‰“å°ç»“æœæ‘˜è¦
        if summary and args.verbose:
            print("\nğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
            print(f"  æ€»å¤„ç†æ–‡ä»¶æ•°: {summary.get('total_files_processed', 0)}")
            print(f"  ä½¿ç”¨è¿›ç¨‹æ•°: {summary.get('max_workers', 0)}")
            
            # è¯­è¨€åˆ†å¸ƒ
            lang_dist = summary.get('language_distribution', {})
            if lang_dist:
                print(f"  è¯­è¨€åˆ†å¸ƒ: {dict(lang_dist)}")
            
            # è¾“å‡ºæ–‡ä»¶
            saved_files = summary.get('saved_files', {})
            if saved_files:
                print("  è¾“å‡ºæ–‡ä»¶:")
                for format_type, file_path in saved_files.items():
                    file_name = Path(file_path).name
                    print(f"    {format_type.upper()}: {file_name}")
        
        print("\nâœ… å¹¶è¡Œå¤„ç†å®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 